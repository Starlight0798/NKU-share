{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 目标检测：口罩佩戴检测  \n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1.实验介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 实验背景  \n",
    "\n",
    "今年一场席卷全球的新型冠状病毒给人们带来了沉重的生命财产的损失。  \n",
    "有效防御这种传染病毒的方法就是积极佩戴口罩。  \n",
    "我国对此也采取了严肃的措施，在公共场合要求人们必须佩戴口罩。  \n",
    "在本次实验中，我们要建立一个目标检测的模型，可以识别图中的人是否佩戴了口罩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 实验要求\n",
    "\n",
    "1）建立深度学习模型，检测出图中的人是否佩戴了口罩，并将其尽可能调整到最佳状态。  \n",
    "2）学习经典的模型 MTCNN 和 MobileNet 的结构。  \n",
    "3）学习训练时的方法。  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 实验环境\n",
    "\n",
    "可以使用基于 Python 的 OpenCV 、PIL 库进行图像相关处理，使用 Numpy 库进行相关数值运算，使用 Pytorch 等深度学习框架训练模型等。\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 注意事项  \n",
    "+ Python 与 Python Package 的使用方式，可在右侧 `API文档` 中查阅。\n",
    "+ 当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动 Kernel 解决（左上角『Kernel』-『Restart Kernel』）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 参考资料\n",
    "+ 论文 Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks：https://kpzhang93.github.io/MTCNN_face_detection_alignment/\n",
    "+ OpenCV：https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html\n",
    "+ PIL：https://pillow.readthedocs.io/en/stable/\n",
    "+ Numpy：https://www.numpy.org/\n",
    "+ Scikit-learn： https://scikit-learn.org/\n",
    "+ PyTorch：https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 实验思路\n",
    "\n",
    "针对目标检测的任务，可以分为两个部分：目标识别和位置检测。  \n",
    "通常情况下，特征提取需要由特有的特征提取神经网络来完成，如 VGG、MobileNet、ResNet 等，这些特征提取网络往往被称为 Backbone 。而在 BackBone 后面接全连接层(FC)就可以执行分类任务。  \n",
    "但 FC 对目标的位置识别乏力。经过算法的发展，当前主要以特定的功能网络来代替 FC 的作用，如 Mask-Rcnn、SSD、YOLO 等。  \n",
    "我们选择充分使用已有的人脸检测的模型，再训练一个识别口罩的模型，从而提高训练的开支、增强模型的准确率。\n",
    "\n",
    "**常规目标检测：**  \n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/20200914162156.png\" width=500px/>\n",
    "\n",
    "\n",
    "\n",
    "**本次案例：**   \n",
    "\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/20200918102630.png\" width=500px/>\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 导入 Python 第三方库（包）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "select": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# 忽视警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 导入已经写好的 Python 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "select": true
   },
   "outputs": [],
   "source": [
    "from torch_py.Utils import plot_image\n",
    "from torch_py.MTCNN.detector import FaceDetector\n",
    "from torch_py.MobileNetV1 import MobileNetV1\n",
    "from torch_py.FaceRec import Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 数据集介绍\n",
    "\n",
    "数据信息存放在 `/datasets/5f680a696ec9b83bb0037081-momodel/data` 文件夹下。    \n",
    "该文件夹主要有文件夹 `image`、文件 `train.txt` 、文件夹 `keras_model_data` 和文件夹 `mindspore_model_data`共四部分：\n",
    "+ **image 文件夹**：图片分成两类，戴口罩的和没有戴口罩的  \n",
    "+ **train.txt**：  存放的是 image 文件夹下对应图片的标签（keras 版本作业需要用到）  \n",
    "+ **keras_model_data** 文件夹：存放 keras 框架相关预训练好的模型 （keras 版本作业需要用到）\n",
    "+ **mindspore_model_data** 文件夹：存放 mindspore 框架相关预训练好的模型（mindspore 版本作业需要用到）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集路径\n",
    "data_path = \"./datasets/5f680a696ec9b83bb0037081-momodel/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们尝试读取数据集中戴口罩的图片及其名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是训练集中的正样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_num = 4\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i in range(mask_num):\n",
    "    sub_img = cv2.imread(data_path + \"/image/mask/mask_\" + str(i + 101) + \".jpg\")\n",
    "    sub_img = cv2.cvtColor(sub_img, cv2.COLOR_RGB2BGR)\n",
    "    ax = fig.add_subplot(4, 4, (i + 1))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"mask_\" + str(i + 1))\n",
    "    ax.imshow(sub_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是训练集中的负样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomask_num = 4\n",
    "fig1 = plt.figure(figsize=(15, 15))\n",
    "for i in range(nomask_num):\n",
    "    sub_img = cv2.imread(data_path + \"/image/nomask/nomask_\" + str(i + 130) + \".jpg\")\n",
    "    sub_img = cv2.cvtColor(sub_img, cv2.COLOR_RGB2BGR)\n",
    "    ax = fig1.add_subplot(4, 4, (i + 1))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"nomask_\" + str(i + 1))\n",
    "    ax.imshow(sub_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 调整图片尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox_image(image, size):\n",
    "    \"\"\"\n",
    "    调整图片尺寸\n",
    "    :param image: 用于训练的图片\n",
    "    :param size: 需要调整到网络输入的图片尺寸\n",
    "    :return: 返回经过调整的图片\n",
    "    \"\"\"\n",
    "    new_image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看图片尺寸调整前后的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 PIL.Image 读取图片\n",
    "read_img = Image.open(\"test1.jpg\")\n",
    "read_img = np.array(read_img)\n",
    "print(\"调整前图片的尺寸:\", read_img.shape)\n",
    "read_img = letterbox_image(image=read_img, size=(50, 50))\n",
    "read_img = np.array(read_img)\n",
    "print(\"调整前图片的尺寸:\", read_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 制作训练时所需的批量数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch** 读取数据虽然特别灵活，但是还是具有特定的流程的，它的操作顺序为：\n",
    "\n",
    "+ 创建一个 `Dataset` 对象，该对象如果现有的 `Dataset` 不能够满足需求，我们也可以自定义 `Dataset`，通过继承 `torch.utils.data.Dataset`。在继承的时候，需要 `override` 三个方法。\n",
    "    + `__init__`： 用来初始化数据集\n",
    "    + `__getitem__`：给定索引值，返回该索引值对应的数据；它是python built-in方法，其主要作用是能让该类可以像list一样通过索引值对数据进行访问\n",
    "    + `__len__`：用于len(Dataset)时能够返回大小\n",
    "+ 创建一个 `DataLoader` 对象\n",
    "+ 不停的 循环 这个 `DataLoader` 对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 第一步：创建一个 `Dataset` 对象\n",
    "\n",
    "**torchvision.datasets.ImageFolder** 是一个通用的数据加载器，常见的用法如下：\n",
    "> dataset=torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=<function default_loader>, is_valid_file=None)\n",
    "    \n",
    "+ **参数详解**：\n",
    "    + root：图片存储的根目录，即各类别文件夹所在目录的上一级目录。\n",
    "    + transform：对图片进行预处理的操作（函数），原始图片作为输入，返回一个转换后的图片。\n",
    "    + target_transform：对图片类别进行预处理的操作，输入为 target，输出对其的转换。如果不传该参数，即对 target 不做任何转换，返回的顺序索引 0,1, 2…\n",
    "    + loader：表示数据集加载方式，通常默认加载方式即可。\n",
    "    + is_valid_file：获取图像文件的路径并检查该文件是否为有效文件的函数(用于检查损坏文件)\n",
    "    \n",
    "+ 返回的 dataset 都有以下三种属性：\n",
    "    + dataset.classes：用一个 list 保存类别名称\n",
    "    + dataset.class_to_idx：类别对应的索引，与不做任何转换返回的 target 对应\n",
    "    + dataset.imgs：保存(img-path, class) tuple 的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 创建一个 `DataLoader` 对象\n",
    "\n",
    "`DataLoader` 是 `torch` 给你用来包装你的数据的工具，所以你要将( numpy array 或其他) 数据形式装换成 Tensor, 然后再放进这个包装器中。 使用 `DataLoader` 帮助我们对数据进行有效地迭代处理。\n",
    "\n",
    "> torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=False,\n",
    " sampler=None,\n",
    " batch_sampler=None,\n",
    " num_workers=0,\n",
    " collate_fn=<function default_collate>,\n",
    " pin_memory=False,\n",
    " drop_last=False,\n",
    " timeout=0,\n",
    " worker_init_fn=None)\n",
    "    \n",
    "- **常用参数解释**：\n",
    "    + dataset (Dataset): 是一个 DataSet 对象，表示需要加载的数据集\n",
    "    + batch_size (int, optional): 每一个 batch 加载多少组样本，即指定 batch_size ，默认是 1 \n",
    "    + shuffle (bool, optional): 布尔值 True 或者是 False ，表示每一个 epoch 之后是否对样本进行随机打乱，默认是 False\n",
    "\n",
    "    + sampler (Sampler, optional): 自定义从数据集中抽取样本的策略，如果指定这个参数，那么 shuffle 必须为 False\n",
    "    + batch_sampler (Sampler, optional): 与 sampler 类似，但是一次只返回一个 batch 的 indices（索引），需要注意的是，一旦指定了这个参数，那么 batch_size,shuffle,sampler,drop_last 就不能再制定了（互斥）\n",
    "\n",
    "    + num_workers (int, optional): 这个参数决定了有几个进程来处理 data loading 。0 意味着所有的数据都会被 load 进主进程，默认为0\n",
    "    + collate_fn (callable, optional): 将一个 list 的 sample 组成一个 mini-batch 的函数（这个还不是很懂）\n",
    "    + pin_memory (bool, optional): 如果设置为True，那么 data loader 将会在返回它们之前，将 tensors 拷贝到 CUDA 中的固定内存（CUDA pinned memory）中\n",
    "\n",
    "    + drop_last (bool, optional): 如果设置为 True：这个是对最后的未完成的 batch 来说的，比如 batch_size 设置为 64，而一个 epoch只有 100 个样本，那么训练的时候后面的 36 个就被扔掉了，如果为 False（默认），那么会继续正常执行，只是最后的 batch_size 会小一点。\n",
    "    + timeout (numeric, optional): 如果是正数，表明等待从 worker 进程中收集一个 batch 等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容。这个 numeric 应总是大于等于0，默认为0。\n",
    "\n",
    "我们采用以上 2 步进行数据处理，代码展示如下:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data_path, height=224, width=224, batch_size=32,\n",
    "                    test_split=0.1):\n",
    "    \"\"\"\n",
    "    数据处理部分\n",
    "    :param data_path: 数据路径\n",
    "    :param height:高度\n",
    "    :param width: 宽度\n",
    "    :param batch_size: 每次读取图片的数量\n",
    "    :param test_split: 测试集划分比例\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    transforms = T.Compose([\n",
    "        T.Resize((height, width)),\n",
    "        T.RandomHorizontalFlip(0.1),  # 进行随机水平翻转\n",
    "        T.RandomVerticalFlip(0.1),  # 进行随机竖直翻转\n",
    "        T.ToTensor(),  # 转化为张量\n",
    "        T.Normalize([0], [1]),  # 归一化\n",
    "    ])\n",
    "\n",
    "    dataset = ImageFolder(data_path, transform=transforms)\n",
    "    # 划分数据集\n",
    "    train_size = int((1-test_split)*len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    # 创建一个 DataLoader 对象\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "    valid_data_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    return train_data_loader, valid_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './datasets/5f680a696ec9b83bb0037081-momodel/data/image'\n",
    "train_data_loader, valid_data_loader = processing_data(data_path=data_path, height=160, width=160, batch_size=32)\n",
    "\n",
    "def show_tensor_img(img_tensor):\n",
    "    img = img_tensor[0].data.numpy()\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 0, 1)\n",
    "    img = np.array(img)\n",
    "    plot_image(img)\n",
    "    \n",
    "for index, (x, labels) in enumerate(train_data_loader):\n",
    "    print(index, \"\\nfeature:\",x[0], \"\\nlabels:\",labels)\n",
    "    show_tensor_img(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3. MTCNN：人脸检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  MTCNN 解读\n",
    "\n",
    "参考文献：《Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks》  \n",
    "文献与代码地址：https://kpzhang93.github.io/MTCNN_face_detection_alignment/  \n",
    "  \n",
    "论文的主要贡献：  \n",
    "1）**三阶段的级联（cascaded）架构**  \n",
    "2）**coarse-to-fine 的方式**  \n",
    "3）**new online hard sample mining 策略**  \n",
    "4）**同时进行人脸检测和人脸对齐**  \n",
    "5）**state-of-the-art 性能**  \n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/20200918102724.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 3.2 MTCNN 的使用\n",
    "\n",
    "这里直接使用现有的表现较好的 MTCNN 的三个权重文件，它们已经保存在 `torch_py/MTCNN/weights` 文件夹下，路径如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet_path = \"./torch_py/MTCNN/weights/pnet.npy\"\n",
    "rnet_path = \"./torch_py/MTCNN/weights/rnet.npy\"\n",
    "onet_path = \"./torch_py/MTCNN/weights/onet.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过搭建 MTCNN 网络实现人脸检测（搭建模型 py 文件在 torch_py/MTCNN 文件夹） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "# 读取测试图片\n",
    "img = Image.open(\"test.jpg\")\n",
    "# 加载模型进行识别口罩并绘制方框\n",
    "recognize = Recognition()\n",
    "draw = recognize.face_recognize(img)\n",
    "plot_image(draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 4. 口罩识别\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 加载预训练模型 MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MobileNet 的预训练模型权\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "train_data_loader, valid_data_loader = processing_data(data_path=data_path, height=160, width=160, batch_size=32)\n",
    "modify_x, modify_y = torch.ones((32, 3, 160, 160)), torch.ones((32))\n",
    "\n",
    "epochs = 7\n",
    "model = MobileNetV1(classes=2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # 优化器\n",
    "print('加载完成...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 手动调整学习率**(可调参）\n",
    "\n",
    "学习率的手动设置可以使模型训练更加高效。  \n",
    "这里我们设置当模型在两轮迭代后，准确率没有上升，就调整学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率下降的方式，acc三次不下降就下降学习率继续训练，衰减学习率\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                 'max', \n",
    "                                                 factor=0.7,\n",
    "                                                 patience=3)\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e9\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "loss_list = []  # 存储损失函数值\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(train_data_loader, 1)):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred_y = model(x)\n",
    "\n",
    "        # print(pred_y.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        loss = criterion(pred_y, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            best_loss = loss\n",
    "            \n",
    "        loss_list.append(loss)\n",
    "\n",
    "    print('step:' + str(epoch + 1) + '/' + str(epochs) + ' || Total Loss: %.4f' % (loss))\n",
    "torch.save(model.state_dict(), './results/temp.pth')\n",
    "print('Finish Training.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 展示模型训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list,label = \"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 检测图片中人数及戴口罩的人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"test.jpg\")\n",
    "detector = FaceDetector()\n",
    "recognize = Recognition(model_path='results/temp.pth')\n",
    "draw, all_num, mask_nums = recognize.mask_recognize(img)\n",
    "plt.imshow(draw)\n",
    "plt.show()\n",
    "print(\"all_num:\", all_num, \"mask_num\", mask_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 提交结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "口罩佩戴检测模型训练流程, 包含数据处理、创建模型、训练模型、模型保存、评价模型等。训练模型可以参考第 4.3 部分训练模型代码  \n",
    "如果对训练出来的模型不满意, 你可以通过调整模型的参数等方法重新训练模型, 直至训练出你满意的模型。  \n",
    "如果你对自己训练出来的模型非常满意, 则可以提交作业!  \n",
    "\n",
    "注意：\n",
    "\n",
    "1. 你可以在我们准好的接口中实现深度学习模型（若使用可以修改函数接口），也可以自己实现深度学习模型。\n",
    "2. 写好代码后可以在 Py 文件中使用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 进行模型训练。\n",
    "3. **使用离线训练模型必须保存在 results 文件夹**。    \n",
    "4. 将自己认为最佳模型保存在 result 文件夹，其余模型备份在项目中其它文件夹，方便您加快测试通过。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "===========================================  实现自己的深度学习模型代码答题区域  ===========================================\n",
    "\n",
    "双击下方区域开始编写  **数据处理**、**创建模型**、**训练模型**、**保存模型**  和  **评估模型**  等部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.加载数据并进行数据处理\n",
    "\n",
    "# 2.如果有预训练模型，则加载预训练模型；如果没有则不需要加载\n",
    "\n",
    "# 3.创建模型和训练模型，训练模型时尽量将模型保存在 results 文件夹\n",
    "\n",
    "# 4.评估模型，将自己认为最佳模型保存在 result 文件夹，其余模型备份在项目中其它文件夹，方便您加快测试通过。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 提交结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业要求及注意事项**：    \n",
    "\n",
    "1.使用上述学到的方法，训练自己的口罩识别模型，尽可能提高准确度。将训练好的模型保存在 results 文件夹下。             \n",
    "2.点击左侧栏`提交结果`后点击【生成文件】则需要勾选与预测 predict() 函数的 cell相关的其它cell ，并将其转化成为 main.py 文件。                       \n",
    "3.请导入必要的包和第三方库以及该模型所依赖的 py 文件 (包括此文件中曾经导入过的)。             \n",
    "4.请加载你认为训练最佳的模型，即请按要求填写模型路径。              \n",
    "5.predict() 函数的输入输出及函数名称请不要改动。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  ===========================================  \n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "select": true
   },
   "outputs": [],
   "source": [
    "from torch_py.Utils import plot_image\n",
    "from torch_py.MTCNN.detector import FaceDetector\n",
    "from torch_py.MobileNetV1 import MobileNetV1\n",
    "from torch_py.FaceRec import Recognition\n",
    "from torch_py.FaceRec import Recognition\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------------- 请加载您最满意的模型 ----------------------------\n",
    "# 加载模型(请加载你认为的最佳模型)\n",
    "# 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "# 如果你的模型是在 results 文件夹下的 dnn.h5 模型，则 model_path = 'results/temp.pth'\n",
    "model_path = 'results/temp.pth'\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def predict(img):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param img: cv2.imread 图像\n",
    "    :return: 预测的图片中的总人数、其中佩戴口罩的人数\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    # 将 cv2.imread 图像转化为 PIL.Image 图像，用来兼容测试输入的 cv2 读取的图像（勿删！！！）\n",
    "    # cv2.imread 读取图像的类型是 numpy.ndarray\n",
    "    # PIL.Image.open 读取图像的类型是 PIL.JpegImagePlugin.JpegImageFile\n",
    "    if isinstance(img, np.ndarray):\n",
    "        # 转化为 PIL.JpegImagePlugin.JpegImageFile 类型\n",
    "        img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    recognize = Recognition(model_path)\n",
    "    img, all_num, mask_num = recognize.mask_recognize(img)\n",
    "    # -------------------------------------------------------------------------\n",
    "    return all_num,mask_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入图片路径和名称\n",
    "img = cv2.imread(\"test1.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "all_num, mask_num = predict(img)\n",
    "# 打印预测该张图片中总人数以及戴口罩的人数\n",
    "print(all_num, mask_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
